import torch
import itertools
from unittest import TestCase, main, SkipTest
from rtp_llm.config.gpt_init_model_parameters import GptInitModelParameters
from rtp_llm.utils.model_weight import W
from rtp_llm.models_py.modules.rocm.norm import QKRMSNorm, FusedQKRMSNorm
from torch import dtype as _dtype
import math
from torch.profiler import profile, ProfilerActivity, record_function


class FusedQKRMSNormTest(TestCase):
    DTYPES = [torch.half, torch.bfloat16]
    NUM_TOKENS = [7, 83, 4096]
    HEAD_NUM = [40]
    KV_HEAD_NUM =  [40, 8, 4]
    SIZE_PER_HEAD = [128]

    # DTYPES = [torch.bfloat16]
    # NUM_TOKENS = [4096]
    # HEAD_NUM = [40]
    # KV_HEAD_NUM =  [40]
    # SIZE_PER_HEAD = [128]

    def setUp(self) -> None:
        if not torch.cuda.is_available():
            raise SkipTest("CUDA is not available")
        torch.set_default_device("cuda")


    def _run_fused_qk_rmsnorm_test(self, num_tokens: int, head_num: int, kv_head_num: int, size_per_head: int, dtype: _dtype):
        torch.manual_seed(0)

        hidden_size = head_num * size_per_head + 2 * kv_head_num * size_per_head

        q_weight = torch.randn(size_per_head, dtype=dtype)
        k_weight = torch.randn(size_per_head, dtype=dtype)

        qkrmsnorm = QKRMSNorm(q_weight, k_weight, head_num, kv_head_num, size_per_head)
        fused_qkrmsnorm = FusedQKRMSNorm(q_weight, k_weight, head_num, kv_head_num, size_per_head)

        x = torch.randn(num_tokens, hidden_size, dtype=dtype)

        # for _ in range(5):
        #     # out = qkrmsnorm(x)
        #     out = fused_qkrmsnorm(x)
        # with profile(activities=[ProfilerActivity.CUDA], record_shapes=True) as prof:
        #     for _ in range(10):
        #         # out = qkrmsnorm(x)
        #         out = fused_qkrmsnorm(x)
        # print(prof.key_averages().table(sort_by="cuda_time_total", row_limit=100))

        self.assertTrue(torch.allclose(qkrmsnorm(x), fused_qkrmsnorm(x), atol=1e-2, rtol=1e-2))

    def test_fusedqkrmsnorm(self):
        for params in itertools.product(
                self.NUM_TOKENS,
                self.HEAD_NUM,
                self.KV_HEAD_NUM,
                self.SIZE_PER_HEAD,
                self.DTYPES,
        ):
            with self.subTest(
                    num_tokens=params[0],
                    head_num=params[1],
                    kv_head_num=params[2],
                    size_per_head=params[3],
                    dtype=params[4]
            ):
                self._run_fused_qk_rmsnorm_test(*params)


if __name__ == '__main__':
    main()
