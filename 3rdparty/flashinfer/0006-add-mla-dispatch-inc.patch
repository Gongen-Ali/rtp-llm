commit 38c8d43feabb84d2f98fbdc8b31f7bed3cff8f37
Author: baowending.bwd <baowending.bwd@alibaba-inc.com>
Date:   Mon Feb 24 11:37:38 2025 +0800

    update - add batch_mla_config.inc

diff --git csrc/batch_mla_config.inc csrc/batch_mla_config.inc
new file mode 100644
index 0000000..b8cd59b
--- /dev/null
+++ csrc/batch_mla_config.inc
@@ -0,0 +1,31 @@
+#pragma once
+#include <flashinfer/page.cuh>
+#include <flashinfer/math.cuh>
+#include <flashinfer/layout.cuh>
+#include <flashinfer/utils.cuh>
+#include <flashinfer/pos_enc.cuh>
+#include <flashinfer/fastdiv.cuh>
+#include <flashinfer/attention/variant_helper.cuh>
+#include <flashinfer/attention/mla_params.cuh>
+
+constexpr int HEAD_DIM_CKV = 512;
+constexpr int HEAD_DIM_KPE = 64;
+using IdType = int32_t;
+
+#include "aot_default_additional_params.h"
+#include "aot_extension_utils.h"
+
+
+#define DISPATCH_context(DTypeQ, DTypeKV, DTypeO, IdType, MASK_MODE, HEAD_DIM_CKV, HEAD_DIM_KPE, Params, ...) \
+  {                                                                                               \
+    DISPATCH_mask_mode(mask_mode, MASK_MODE, [&] {                                                \
+      return DISPATCH_PYTORCH_QKV_DTYPE_TO_CTYPE(                                                 \
+          q_scalar_type, kv_scalar_type, DTypeQ, DTypeKV, [&] {                                   \
+            using DTypeO = DTypeQ;                                                                \
+            using DTypeO = DTypeQ; \
+            using Params = MLAParams<DTypeQ, DTypeKV, DTypeO, IdType>; \
+                  __VA_ARGS__();                                                                  \
+                  return true;                                                                    \
+          });                                                                                     \
+    });                                                                                           \
+  }
